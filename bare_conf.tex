%% bare_conf.tex
%% V1.3


% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[a4paper,conference]{IEEEtran}


% *** CITATION PACKAGES ***
%
\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
   \graphicspath{{./}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi




\usepackage[cmex10]{amsmath}



\usepackage{algorithmic}




% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}


\usepackage{mdwmath}
\usepackage{mdwtab}




% *** SUBFIGURE PACKAGES ***
\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



\usepackage[caption=false]{caption}
\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.



% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Random Access Codes for DNA Storage}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Ryan Quinn Ford}
\IEEEauthorblockA{Philipps-University Marburg, Germany \\
Department of Mathematics and Computer Science, Distributed Systems Group \\
Email: ford@informatik.uni-marburg.de
}}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
%\boldmath
With the global amount of data growing at a speed which current storage technologies cannot hold pace with, researchers have looked to DNA for a novel storage solution. DNA provides an unprecedented data density and long-term durability, which is now being actualized for data storage thanks to ever-decreasing sequencing costs. Due to very low read speeds and delicate conditions, it is of significant importance to find ways to more efficiently randomly access data in a DNA store, e.g. retrieving values from keys. In this paper I discuss two current techniques for random access in DNA storage and their capabilities and outlook in regards to scalability and error correction/detection. In addition, I will take a look at the current limitations that face these techniques and what areas they open up to future research.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the conference you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals/conferences frown on
% math in the abstract anyway.

% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% no \IEEEPARstart
% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)
In order to understand the current DNA storage techniques and their limitations, it is necessary to touch upon some underlying biological principles as well as necessary concepts from information science and database systems. The following sections will go over both, which will give us the terminology we need to achieve a deeper understanding of the biochemical and information theoretical constraints that apply. A high-level overview explaining the interest behind this research topic follows, before the details are discussed.

\subsection{High-Level Overview and Reasoning}
There exist a multitude of properties of DNA rendering it as an innovative candidate for data storage, which has led it to become a heavily researched topic over the past decade. The amount of stored data in the world is growing at a rate of 30\% to 40\% a year \cite{globaldatagrowth}, outpacing the growth of today's current storage medium's capabilities. As a result, researchers have recently looked towards new mediums to remedy this problem. DNA sequencing and accompanying technologies have experienced significant cost reduction in past years, making DNA an increasingly attractive medium for the future. 

To understand the appeal, one can first contemplate the theoretical bounds for storage data in a DNA molecule.  An estimate of the information capacity considering reasonable encoding constraints is 1.83 bits per nucleotide \cite{1}, which may sound uninteresting as a storage medium until the physical size of this structure is considered.  A single base pair has a mass of about 330g/mol \cite{2}, which results in a storage capacity of 137.76 zettabytes per gram. This is an improvement of many orders of magnitude over current long term storage mediums, such as magnetic tape \cite{?}.\\

Another appealing aspect of DNA storage is it's robustness. With a half life of 521 years \cite{dnahalflife}, a DNA strand will persist for around 6.8 million years. The current best option for long term data storage is magnetic tape, which, must be replaced around every 10 years.

%{dnahalflife}https://royalsocietypublishing.org/doi/10.1098/rspb.2004.3016

%\hfill mds
 
%\hfill January 11, 2007

\subsection{Underlying Biological Concepts}

\begin{center}
\includegraphics[width=2in]{dna}
\end{center}


\subsubsection{DNA Basics}
Deoxyribonucleic Acid, more commonly referred to as \textbf{DNA}, is the carrier of genetic information in all living beings and our storage medium of interest. A strand of DNA is comprised of four chemical building blocks called \textbf{nucleotides} which occur sequentially in a strand, connected by a sugar-phosphate backbone. Such a strand of nucleotides is commonly referred to as an \textbf{oligo}, short for oligonucleotide.

Each DNA strand has two chemically distinct ends, called 5' and 3', and is made up of nucleotides, also called \textbf{bases}, which are named Adenine, Thymine, Guanine, and Cytosine, and are abbreviated as A, T, G, and C, respectively. Each pairing in a DNA molecule is called a \textbf{base pair} (bp). In these canonical base pairings, Adenine pairs with Thymine, and Guanine pairs with Cytosine. A strand's reverse complement is defined as its sequence of complementary base pairs and swapped 3' and 5' ends.

The primary structure of a DNA molecule is a double-helix, discovered by Watson and Crick in \cite{3}. In this structure, two reversely complementary strands bind to each other in a "twisted ladder" formation, where each nucleotide on one side forms a hydrogen bond with the one on the opposing side in one of two of the canonical pairings. Two binded, complementary strands can be referred to as ds-DNA (doubly stranded DNA), while a single strand can be referred to as ss-DNA (singly stranded DNA).



\subsubsection{Properties relevant to error proneness}
DNA is a living molecule, so it is unwise to map data to it without first taking some biochemical limitations into consideration. One of such limitations stems from \textbf{homopolymers}, regions of a strand which solely consist of repetitions of a single base. It is of critical importance to avoid such homopolymers in the encoding process, as they render a strand more error prone \cite{?} and unstable.

Another important property of a DNA strand is its \textbf{GC Content}, which is defined as the ratio of Guanine and Cytosine bases to the total count of bases in the strand. Having a reasonable GC Content \cite{?} is important to the strand's stability. Oligonucleotides, which will be referred to in later sections as \textbf{oligos}, are simply short DNA sequences of around 100 bases.

Yet another relevant issue is the formation of secondary structures. Secondary structures form when a DNA strand binds to itself or another semi-complementary strand in an undesirable way.

\subsection{DNA in storage}
A container of solution containing ds-DNA molecules is called a DNA pool. Most often, the entirety of the data is not stored in a single container, but rather divided up into many DNA pools in order to avoid the aforementioned conflicts, especially undesirable binding to incorrect data fragments.

\subsection{Random Access}
\begin{figure}
\centering
\includegraphics[width=3.5in]{randomaccess}
\caption{Random Access}
\label{randomaccess}
\end{figure}

Random (direct) access in a storage system implies the ability to access all data fragments in any arbitrary order. The most basic form of random access in a DNA library comes from the separation of files into fragments, which all receive a distinct primer it can be identified by. Because this primer is stored in-silico, one can re-amplify the solution containing a specific DNA fragment on retrieval, effectively directly accessing the desired data. Nonetheless, primer design is a delicate task and the amount of primers that can be used is severely limited. This is partially alleviated by separation of a dataset into $n$ physically separated DNA pools, allowing reuse of the primers and linearly scaling direct access capability.



%[1] https://www.biorxiv.org/content/10.1101/074237v3.full.pdf
%[2] https://www.sciencedirect.com/science/article/abs/pii/S0022283662801004?via%3Dihub

%\subsubsection{Deoxyribonucleic Acid}
%Subsubsection text here.


\subsection{Encoding Data into DNA}
In order to store data into a DNA strand, one must first consider how the data gets mapped to the four available bases. On first glance, one could try assigning each of the four bases a two bit sequence, for example A=00, C=01, T=10, G=11. This simple mapping would mean a byte like 01100011 would get transformed into the base sequence CTAG. Depending on the data format, regions of the binary representation may often repeat itself heavily. If one were to map two bits per base naively as described, this would result in highly error prone strands due to extreme GC Content and long homopolymer regions, among other issues. For these reasons, two main operations are performed on the data in the majority of previous work.

\subsubsection{Rotating Huffman Code}
First, the data is compressed using Huffman coding as seen in \ref{code}. In Huffman coding, a byte sequence is separated into $n$-ary sequences and the relative frequencies of each sequence is calculated. In our case, we use triplets of bits. A binary tree is then generated assigning more probable triplets codes of shorter length in order to store the data more efficiently. This alone, however, does not remedy the problem of repetitive regions. For this, a rotating code is used, which simply ensures that the same base is never repeated more than once. This is achieved by not only choosing the base based on the ternary digit from the Huffman code, but also based on the previous nucleotide.


\begin{figure}
\centering
\includegraphics[width=3.5in]{code}
\caption{Rotating Huffman Code}
\label{code}
\end{figure}

\subsubsection{Erasure Codes}
Due to high error rates when reading the DNA, there must be some redundancy to ensure the data is properly recovered. This is commonly implemented with erasure codes, in which the data sequence is transformed into a longer sequence which can be successfully decoded with only a subset of the characters from the encoding. In current DNA libraries, the redundancy parameter is tuned relatively high \cite{}, which significantly reduces the achieved information density. As sequencing technology improves, the redundancy parameter should be able to be tuned down \cite{} due to lower read errors and improved encoding schemes which are aware of and avoid secondary structure formation.

\subsubsection{Secondary Structure}
Secondary structure formation is another cause of error prone sequences. When the encoded DNA is encoded in such away so that two regions of the same sequence can bind to each other, or when a sequence has a high enough similarity to the reverse complement of a different sequence, undesirable bonds can form that will restrict the ability to work with the DNA library.


\subsection{PCR}
After the data has been mapped to a DNA strand, it is time to synthesize the sequences and prepare them for storage. One aspect of this preparation often involves PCR (Polymerase Chain Reaction), in which each DNA sequence is multiplied millions of times. TODO: Why is this amplification necessary? In this process, after the data has been mapped to the four nucleotides as discussed above, a so-called primer is appended to the sequence. This primer will serve as a marker of the region to be copied by an enzyme called a DNA Polymerase. This copying, called amplification, is a cycle involving the following steps.

\subsubsection{Denaturation}
In a process called denaturation, DNA molecules are split up into its two complementary strands by being heated to a target temperature $T_m$, called the \textit{melting point}. This melting point is defined as the temperature where 50\% of the DNA strands separate. This happens because the heat breaks the hydrogen bonds holding the two strands together. This step is necessary in order to allow the complementary primer sequences to attach to each strand. 
\subsubsection{Annealing}
Once the DNA molecules are split, the environment is cooled back down in a process called annealing. Since the strands are not bonded anymore, there is room for the primer sequences to bond to the complementary primer regions we appended to our data-holding DNA strand.
\subsubsection{Extension}
The DNA polymerase enzyme now finds the primers added in the last step, and recreates the double-helix by adding free nucleotides one by one.
\subsubsection{Repetition}
Now that the polymerase has recreated the original double-helix, the process can cycle, restarting at the denaturation step. The number of copies doubles with each step.

\subsection{Nanopore Sequencing}


\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{pcr}
\caption{PCR Stages}
\label{fig_sim}
\end{figure}


\section{Some Random Access Methods}
In the next section we will explore some current techniques for random access. It is an open research question as to how random access needs to look from the encoding level in order to be scalable. The current available random access mechanisms heavily rely on primer design and orthogonality of the encoded sequences, as well as physical separation.

\subsection{PCR-Based Random Access}
In PCR-Based Random Access, the PCR primers used for amplification before storage are utilized as the main random access mechanism. This was presented in previous works \cite{} where random access was achieved by separating the database into $n$ DNA pools, each with a given amount $k$ of amplified DNA fragments. Each of the $k$ fragments has a unique primer that was used for PCR amplification, so this is what is used as a key to later retrieve the correct fragment. Note that the scalability of this approach depends on the number of available primers for a DNA library, as these can only be reused once per pool for truly individually addressable files.

However, because there are typically around a maximum of 10 primers per DNA pool, there is a limit of $10n$ individually addressable distinct data fragments. In addition, the mapping of key-value pairs as well as a mapping of file to DNA pool location must be stored in-silico for later retrieval. Notwithstanding, one cannot easily scale the number of primers since their design is computationally difficult due to the fact that they must be experimentally verified before use. Not only this, but error rates grow quickly with each additional primer, since they must all be optimally orthogonal to each other in order to reduce the chance of catastrophic failure or incorrect addressing. These limitations suggest that although PCR based random access has scaled well as a first generation random access technique, and is quite robust, it cannot scale well enough to compete with traditional storage mediums. This is especially the case when one considers that there needs to be a physical copy of each DNA pool, and the amount of times random access to a DNA pool can be carried out is limited by the number of physical copies that exist.

In \cite{}, Organick et. al. encoded and stored over 200MB of data spanning across 35 distinct files, each of which were recovered individually and without errors using PCR based random access. The DNA library consisted of more than 13 million DNA oligos in total. They encoded each digital file into megabyte sized blocks before encoding, appending the file address to each block, then applying a Reed-Solomon Code. Reed-Solomon Codes are a type of Erasure Codes that comprise of an inner and outer decoding. Before the data blocks were converted to nucleotides, an outer code was applied that added new blocks to the file containing redundant information. After this, an inner code is generated and applied to each bit sequence, in the process of which the bit string is translated into bases with added redundancy. The main innovation presented in their work was the scalability of PCR-based random access and the creation of a new algorithm to reduce the read coverage needed at sequencing, as sequencing is still heavily error prone \cite{}. They created custom primers and verified them experimentally before use. 

In \cite{}, Yazdi et al. implement a comparable system, except with a focus on maximizing block length to reduce read errors. Because they had longer information strings in each sequence (1000bps), they were able to reach a higher information density of $4.9 \times 10^{20}$ B/g. An address portion was appended to the beginning and end as in \cite{}. They argue, "Instead of storing blocks mimicking the structure and length of reads generated during high-throughput sequencing, we synthesized blocks of length 1000bps tagged at both ends by specially designed address sequences. Adding addresses to short blocks of length 100bps would incur a large storage overhead, while synthesizing blocks longer than 1000bps using current technologies is prohibitively costly." In contrast to \cite{}, \cite{} supported the rewriting of data. However, the scale of this experiment must be considered. Only six Wikipedia articles were stored, comprising in total only 17Kbs of data. This inherently lowers error rates, even considering their delicately crafted encoding scheme. Therefore, these results must be replicated on a larger scale before arguing the superiority of this scheme. 

A problem facing PCR-based random access is destructive operations. Because there is no real separation of data inside a pool, data that is not being addressed will be sequenced and destroyed upon read. This poses a large problem especially because only the directly accessed data is first amplified using PCR, meaning that reads dwindle the supply of less-often accessed data. Most works using PCR-based random access use sequencing techniques that destroy data, more importantly, even data that is not being accessed, on read. The next method attempts to circumvent this restriction by leaving the PCR primers out of random access.

\subsection{Random Access with T7 Promoter}
In \cite{}, Lin et. al. took a different approach to random access, which they named DORIS (Dynamic Operations and Reusable Information Storage). Instead of using PCR primers for addresses, a header is instead appended to the sequence containing a file address and a T7 promoter. The file address hangs off of the sequence as ss-DNA and is used for random access. Random access is achieved by means of magnetic separation, which does not rely on PCR. First, the complement of the hanging ss-DNA is synthesized with a magnetic component \cite{}. This is released in the DNA pool, where it binds to the overhang, which can then be separated from the other sequences magnetically. Next, the RNA polymerase targets the T7 promoter, where they non-destructively transcript the sequence to RNA (in-vitro transcription). The RNA is then converted back into cDNA with reverse transcription, which is then converted back into a double-stranded version (second-strand synthesis reaction). The file operations are carried out in different ways, all exploiting the overhang containing the address.

As argued in the previous section, PCR based random access, although robust, requires physical redundancy because each physical DNA pool can only be accessed once. DORIS circumvents this by means of its separation and in-vitro transcription, allowing the original sequences to return to the DNA pool, and keeping the other info sequences safe from the sequencing monsters (nanopores) TODO.

Using this technique, DORIS not only enables scalable random access with nondestructive reads, but also for additional file operations that are not supported in other works, such as locking, unlocking, renaming, and deleting. In other coding schemes, the direct access is destructive in the sense that each sequence is destroyed upon sequencing. //TODO: Why isn't the sequencing destructive for DORIS as well?


\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{pcrchallenges}
\caption{PCR Challenges}
\label{pcr_challenges}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{doris}
\caption{DORIS}
\label{doris}
\end{figure}

\subsection{Outlook with Microarrays}
An alternative, hypothetical system which has not yet been tested would use DNA microarrays as a random access mechanism. DNA microarrays are essentially grids of DNA binding sites, where each site contains a few (TODO) ss-DNA strands which represent the complements of the address and primer portion of the data we want to retrieve. 

\section{Conclusion}
The presented techniques for achieving random access in DNA storage libraries have brought forth new research problems bringing us closer to the theoretical bound of data we can store in a DNA molecule.





% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}

\bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
  \bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
  \bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
  \bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
  \bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

\end{thebibliography}




% that's all folks
\end{document}


